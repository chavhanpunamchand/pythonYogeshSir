Complex Types
		--> hom+hetro -- dataelements are allowed
		--> backed by datastructure
		--> every datastructure is growable in nature.
		
	List --> 3+
		 --> insertation seq in maintained
		 --> Array --> index based +ve/-ve/
		 -->duplicates allowed
		 -->multiple Nonetypes allowed
		--> mutable --> add		remove 		read		update
				
college --> example->		
	--> append/extend/insert		--add		-->add	
	--> remove/pop/clear			--remove
	-->
	--> count
	--> copy						-->set/dict/list


-->	SIR2 PAI C3E  --> Software Engineering-->
	SIR2 PAI C3E --> LIST
	S--> sort
	I -->insert
	R -->reverse
	R -- remove
	P --> pop
	A -->append
	I -- index--
	C--clone
	C-Copy
	Clear
	E -- extend
	
	

sir2 pai c3e-->

append()--> single element --> group of element--> len+1
extend --> group of element					   --> len + group len

values1 = [10,20,30,40,50]
values2 = [10,20,30]

#values1.append(values2)--> len--	5+1	--> [10,20,30,40,50,[10,20,30]]
values1.append(100)--> len -->5 +1 --> 6 [10,20,30,40,50,60]

values1.extend(100);	--> error -- required group of elements
values1.extend(values2) --> len --> 5+3-->[10,20,30,40,50,10,20,30]
					--> group elements-->no of times append 


->Set Implementations-->

'''
realpython
data-flair
journaldev
'''

values = []
values.pop()    #p         
values.clear()  #c
values.remove() #r
values.copy()   #c
values.append() #a
values.index()  #i
values.extend() #e
values.sort()   #s
values.insert() #i
values.reverse() #

list -->array--> array -- functionality --> list

-------------->set implementations--------------------
set --> 3+
		--> only unique elements --> duplicates not allowed
		--> insertation seq is not maintained
		--> single nonetype allowed
		--> set Datastructure --- Hashtable --> what is hashtable-- how it works
		
		
--> list -->	
	USE CASES-->
			searching/retrival better --> index based operation--> internally -- array-- continous mem--continous
			insertation/deletation --> array - fixed --> creates new array--> shifting--> everytime--> grow-- array -->
												creates new array -- shifting--> slow-list
								
								[None  None  None  None  None]

								[None  None  None  None  None	None  None  None  None  None]
											
	linkedlist -->
			not continous allocation -->
					--> fixed in size --**
			
				12		23		32 		42

		doubly linked list --> two direction -- frwd/backword
												next -- prev
		first node										
			[prev 12 5x]			 		[1x  32 28xx]	[ 5x 42 None]
				1x					   				5x				288x

			[12 10x]			[23 5x] 		[ 32 28xx]	[ 42 None]	-- singly- frwd -direction
				1x					   10x				5x				288x



				 0   1  2  3  4
				[10 21 30 32 33] -- Array
			
			
		array --> searching --> index known asel tr-->
			1	2	3	-		-		-		10	-->
			11	65	78	98 33 	23	24	90	96	263		--> 9
				--> index is known --> 1	---> best case
				--> index is unknown-->
							element present--> len-1
							not sure about the element --> len	--> worst case
							
			1...10 = (n * (n+1))/2 =	10*(10+1)= 110	--> 110/2 --> 55/10-->5.5
			
			
		LinkedList -->	searching worst --> always needs to start from first
						insertion/deletation -- best --> no shifting--> 
						
	--> array -- searching/retrival
	--->linkedlist---insertion/deletation
	
--> what --> group of element --> searching/retrival and insertion/deletion
										 which type is best- -**
										 
										 
Hashtable --> search/retrive -- insert/delete
					
				set-->	Hashtable --> based on hashing--> indexing-->
					
		1-100-->	seq --
			groups--buckets				1-10
										11-20
										21-30
					  4---25			10---10		no-bucket
1	--1					1+1				1+1

22	--22				1+22			3+2

25			1-25	

35	 35					2+10			4+5

50			26-50


75	 75		51-75		3+25			8+5



100	100		76-100		4+25			10+10
-----------	
worst ->100			  -->4+25			10+10
	n				no of buckets+max no in one buckets
					29					 20
										
					55282 -->4			52 -->6+10

	125--->
					
					
					13+9-->
					
indexing-- improves searching perfm-->**
				-->creating buckets--> and searching elements
						-- only in that bucket instead all.
						
->govt -- files --> year wise-- oranganized-->
		--> bucket --> 2008
		1989 ---> 31 years--> 	31 buckets -->
						2008--> month wise-->
					
					
	12	34	87	65	67	83	21	44	19	10 		1276167216
	
	n%no of buckets -->
	
	12/5	--> [0 1 2 3 4]-->		55--?
	1276167216%8-->												2
	1276167216%5-->								%5 -->0		-- not present--
	
0	[65 442x]	[10	next]			-----> l1

					442x
1	[21 next]						--> l2


2	[12 28x]	[87	8x]		[67 next]		--> 3
		45x			28x			8x
		
3	[83 next]


4	[34 71x]	[44 11x]	[19 ]		--> l5
	  87x			71x		11x
				
					
array-->	[l1	l2	l3	l4	l5]	--->

		67%5 --> 2-1= ---> 1-->
				
				
				we are not deciding-- > hashtable -->8-->
				

hashtable-- indexing-- rehashing-->
set properties-->
	all methods->
		-->


ans return			will change ori
difference		--- difference_update		--> A-B -> only from A-- which are not present in B
intersection	--> intersection_update		--> common from both
symetricdiff	-->symetricdiff_update		--> uncommon from both
union			-->update					--> unique from both


s1.issubset(s2) --> checks all s1 elements present inside s2 --> true->	s2.issuperset(s1)
																false	s2.issuperset(s1)
																
s1.isdisjoint(s2) --> all elements shud be seperate-- nothing in common








set -- indexing not allowed --> internally elements are inside
			linked--> array- -- hashtable-




0	---------------

1	--------------

2	----------------


3	----------------
hashtable- --?
				searching -- fast
				inseration/delete--> fast--> linkedlist
				
			rehash --> 0.75 filled--hashtable-- double-->
									%5		%10
					
					perfomance-- increase
					
					
hashtable-- searching/insetion/delete--
			disadvantges--> duplicates not allowed
							--> duplicate-- retrive/delete
							

rehashing-->
													which element/bucket size --> >0.75
										hashtable- -> 	rehash		
													
	120 181 11 281 22 192 92 7 17 44	--> set -->no seq
										--> duplicate		
				281%10 --> 1				8/10-->0.8	<0.75 --> TRUE/FALSE
							
	11	21  11
					11 --> user perpective same--> memories--?
					11 --> content
					
					yogesh -- >hike --> retrive-->delete-->problems*
					set never allows duplicate--> hashtable-->
	0
	
	1	Yogesh	21	yogesh
	
	2


interview--> crack--
	set -->
	
			
	0
	
	1	
	
	2	2 					1		
	
	3
	
	4
	
	5
	
	6
	
	7	7					1
	
	
	
	
	0.75 --> REHASH ->
	
	--> 1	2	3	4  	5	6	7	8	9	10		--> empty
		*		*	*

			
			16/20-->

perfomance--> buckets-- more-- than-- one element -- slow
			element1 --> empty
			element2--> empty
			element3 --> empty
	**		element4 ?--> filled**-->bucket--2 --> perfomance--slow
			
				4/5--> 0.75--> space--> 75% -- problem sure-->
								increase space-->
												
1000 -- random numbers--> worst case--> uniform distribution--200
			uniform nasel- max of bucket nos
	
	1000 ---<n random>
			
			1001	10241	2932971	228781

0	0

1	---> 1000

2	0

3	0


4	0

	uniform distribution--200--*
	--> 200--> best case--*
	
			worst - case -- 900

-----------------------Code--------------------------
import copy

#72 76 478 102

#list--> copy---set-->copy-->dict-->copy ---> shallow copy--> changes in original/duplicate--> make diff-in other
# -->

values1 = [10,20,30,[100,200]]
#values2 =values1.copy()    # method from list
values2=copy.deepcopy(values1) #method from another module
values2[3][1]="XXX" #first
print(values1) #first --> only in original--
print(values2)  #second

import sys
sys.exit(0)

#[1,31,241,351,123,4,767,]--> products --> barcode-->

set1 = {100,200}
set2 = {10,20,30,60,70,80}

flag = set1.isdisjoint(set2)
print(flag)

import sys
sys.exit(0)

flag = set2.issuperset(set1) # will be always true for set1.issubset(set2)
print(flag)



import sys
sys.exit(0)
    # returns ans
ans = set1.union(set2)  #combination --> unique -- remove duplicates --> keep unique of both
print(set1) #10,20,30,40,50
print(set2)#10,20,30,60,70,80
print(ans)#10,20,30,40,50,60,70,80

print('----------------------------')
      # nothing in return --< None
ans = set1.update(set2)
print(set1)##10,20,30,40,50,60,70,80
print(set2)#10,20,30,60,70,80
print(ans)#None



ans = set1.symmetric_difference(set2) # uncommon--both
print(set1)#10,20,30,40,50
print(set2)#10,20,30,60,70,80
print(ans)#40,50,60,70,80
print('-------------------------------------')

print(set1 ^ set2)  #40,50,60,70,80

print('-------------------------------------')
ans = set1.symmetric_difference_update(set2)
print(set1) ##40,50,60,70,80
print(set2)#10,20,30,60,70,80
print(ans)#None






ans = set1.intersection(set2) #only common
print(set1) #10,20,30,40,50
print(set2) #10,20,30,60,70,80
print(ans)#10,20,30
print('-------------------------------------')
print(set1 & set2) #10,20,30
print('-------------------------------------')
ans = set1.intersection_update(set2) #only common
print(set1)#10,20,30
print(set2)#10,20,30,60,70,80
print(ans)#None


ans = set2.intersection_update(set1) #only common
print(set1)#10,20,30,40,50
print(set2)#10,20,30
print(ans)#None





ans = set1.difference(set2) # A-B   --> only elements inside A-not matching to B set
print(set1) #10,20,30,40,50
print(set2) #10,20,30,60,70,80
print(ans)  #40,50
print('---------------------------')
print(set2-set1) #60,70,80
print('--------------------')
ans = set1.difference_update(set2) # A-B   --> only elements inside A-not matching to B set
print(set1) #40,50
print(set2) #10,20,30,60,70,80
print(ans)  #None




#values = {10,20,33,44,55,11,5,38,34}






                                #{33, 34, 5, 38, 10, 11, 44, 20, 55}
                                #{33, 34, 5, 38, 10, 11, 44, 20, 55}
print(values)                   #{33, 5, 10, 11, 44, 20, 55}

#values = {10,20,28,345,233,30,10,30,40,50} #hashtable--> bucket--?





import sys
sys.exit(0)
print(values)
print(values)
ans = values.pop() # will remove first element--> after placing it inside hashtable
                # list-- index--> based on index--remove

print(values)
print(ans)

import sys
sys.exit(0)
values.copy() #shallow copy
values.remove(10) # will remove-- matching element
                  #list remove-- first matching element
values.clear() # will make set empty
